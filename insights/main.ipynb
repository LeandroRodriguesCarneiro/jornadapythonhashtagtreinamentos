{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# importando base de dados.\n",
    "df = pd.read_csv('cancelamentos.csv')\n",
    "\n",
    "# removendo colunas desnecessárias.\n",
    "df.drop(columns=['CustomerID'], inplace=True)\n",
    "\n",
    "# removendo linhas com dados em branco.\n",
    "df.dropna(inplace=True)\n",
    "#display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo colunas com muitos dados diferentes, pois são mais fáceis de analisar com gráficos.\n",
    "colmuns = list(df.columns)\n",
    "for colmun in ['tempo_como_cliente','idade','frequencia_uso', 'dias_atraso', 'total_gasto','meses_ultima_interacao']:\n",
    "    colmuns.remove(colmun)\n",
    "\n",
    "# visualizando as quantidades e porcentagem das colunas da base de dados.\n",
    "for colmun in colmuns:\n",
    "    display(df[colmun].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "    display(df[colmun].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando as quantidades e porcentagem das colunas da base de dados.\n",
    "colmuns = list(df.columns)\n",
    "colmuns.remove('cancelou')\n",
    "\n",
    "for colmun in colmuns:\n",
    "    display(df[colmun].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "    display(df.groupby(colmun).mean(numeric_only=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "for colmun in df.columns:\n",
    "    graph = px.histogram(df, x = colmun, color=\"cancelou\", width=600)\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com os problemas identificados, aplicam-se as tratativas para comparar com o resultado inicial.\n",
    "\n",
    "print('Estatisticas iniciais')\n",
    "display(df['cancelou'].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "display(df['cancelou'].value_counts())\n",
    "\n",
    "print('Removendo os contratos mensais')\n",
    "df_new = df[df['duracao_contrato'] != 'Monthly']\n",
    "display(df_new['cancelou'].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "display(df_new['cancelou'].value_counts())\n",
    "\n",
    "print('Removendo resolvendo o problema antes de 5 ligacoes')\n",
    "df_new = df[df['ligacoes_callcenter'] < 5]\n",
    "display(df_new['cancelou'].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "display(df_new['cancelou'].value_counts())\n",
    "\n",
    "print('Nao permitindo mais de 20 dias de atraso no pagamento')\n",
    "df_new = df[df['dias_atraso'] < 20]\n",
    "display(df_new['cancelou'].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "display(df_new['cancelou'].value_counts())\n",
    "\n",
    "print('Aplicando todas ao memsmo tempo')\n",
    "df_new = df[(df['duracao_contrato'] != 'Monthly') & (df['ligacoes_callcenter'].lt(5)) & (df['dias_atraso'].lt(20))]\n",
    "display(df_new['cancelou'].value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "display(df_new['cancelou'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando a entropia e ganho de informação das colunas.\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    counter = Counter(data)\n",
    "    total_samples = len(data)\n",
    "    entropy = 0.0\n",
    "    for count in counter.values():\n",
    "        probability = count / total_samples\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(data, attribute, target):\n",
    "    entropy_before_split = calculate_entropy(data[target])\n",
    "    values = data[attribute].unique()\n",
    "    total_samples = len(data)\n",
    "    entropy_after_split = 0.0\n",
    "\n",
    "    for value in values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        weight = len(subset) / total_samples\n",
    "        entropy_after_split += weight * calculate_entropy(subset[target])\n",
    "\n",
    "    information_gain = entropy_before_split - entropy_after_split\n",
    "    return information_gain\n",
    "\n",
    "colmuns = list(df.columns)\n",
    "colmuns.remove('cancelou')\n",
    "\n",
    "print('Ganho de informacao da base de dados sem modificacao')\n",
    "list_information_gain = []\n",
    "for colmun in colmuns:\n",
    "    dict_data = {colmun: calculate_information_gain(df, colmun, 'cancelou')}\n",
    "    list_information_gain.append(dict_data)\n",
    "\n",
    "list_information_gain = sorted(list_information_gain, key= lambda x: list(x.values())[0], reverse=True)\n",
    "display(list_information_gain[:5])\n",
    "\n",
    "print('Ganho de informacao da base de dados com as modificacoes')\n",
    "list_information_gain = []\n",
    "for colmun in colmuns:\n",
    "    dict_data = {colmun: calculate_information_gain(df_new, colmun, 'cancelou')}\n",
    "    list_information_gain.append(dict_data)\n",
    "\n",
    "list_information_gain = sorted(list_information_gain, key= lambda x: list(x.values())[0], reverse=True)\n",
    "display(list_information_gain[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
